#!/usr/bin/env python
import sys
import os
import argparse
import time
import dup_pipe as dp
import allele_backbone as ab
import allele_gmap as ag
import allele_blast as abl

#### workflow ####
## 0. 目的：目前的方法鉴定到的假阳性等位和paralog有点多，所以需要去掉一些。
## 1. 首先鉴定重复分类，将其分为tandem (TD)/Dispersed (DPD)/Proximal (PD) 等, DPD和PD和都归为-P, TD为-T
## 2. 构建等位表的主体方法不变，但在构建等位表时去掉这三种重复的基因
## 3. 因为去掉了三类重复基因，所以每个同源染色体上的基因座理论上只有一个基因，pull down 多余的那个形成新的等位基因。
## 4. 将三类重复加进等位表中。


def time_print(info):
	print("\033[32m%s\033[0m %s"%(time.strftime('[%H:%M:%S]',time.localtime(time.time())), info))


def get_opts():
	group = argparse.ArgumentParser()
	group.add_argument('-r', '--ref', help="reference fasta", required=True)
	group.add_argument('-d', '--ref_cds', help="CDS fasta of ref", required=True)
	group.add_argument('-f', '--ref_gff3', help="GFF3 file of ref", required=True)
	group.add_argument('-c', '--cds', help="CDS fasta of polyploid", required=True)
	group.add_argument('-g', '--gff3', help="GFF3 file of polyploid", required=True)
	group.add_argument('-n', '--num_allele', help="number of allele", type=int, required=True)
	group.add_argument('-m', '--is_mono', help="If your reference fasta is mono assembly of polyploid, add this argument", action="store_true")
	group.add_argument('-b', '--blast_count', help="blast count, default: 2", type=int, default=2)
	group.add_argument('-i', '--blast_identity', help="threshold of blast identity, default: 80", type=float, default=80)
	group.add_argument('-e', '--TE', help="TE gff3 for filtering, default: \"\"", default="")
	group.add_argument('-j', '--TE_overlap', help="threshold of TE overlap, default: 0.3, only effect when TE is not NULL", type=float, default=0.3)
	group.add_argument('-w', '--workdir', help="workdir, default: wrkdir", default="wrkdir")
	group.add_argument('-t', '--threads', help="threads, default: 12", default=12, type=int)
	return group.parse_args()


def AlleleFinder(ref, ref_cds, ref_gff3, cds, gff3, na, is_mono, blast_count, iden_thres, TE, TE_thres, wrkdir, threads):
	if not os.path.exists(wrkdir):
		os.mkdir(wrkdir)
	
	ref = os.path.abspath(ref)
	ref_cds = os.path.abspath(ref_cds)
	ref_gff3 = os.path.abspath(ref_gff3)
	cds = os.path.abspath(cds)
	gff3 = os.path.abspath(gff3)
	if TE != "":
		TE = os.path.abspath(TE)
	
	script_dir = sys.path[0]
	time_print("Entering: %s"%wrkdir)
	os.chdir(wrkdir)

	time_print("Step1: running MCScanX")
	mcs_dir = "01.mcscanx/xyz/xyz.html"
	parent_dir = os.path.abspath(mcs_dir).replace("xyz.html", "")
	dup_dir = parent_dir + "output_directory"
	tandem_file = os.path.abspath("01.mcscanx/xyz/xyz.tandem")
	hap_blast_file = os.path.abspath("01.mcscanx/xyz/xyz.blast")
	if not os.path.exists(mcs_dir):
		cmd = "python %s/run_MCScanX.py %s %s 01.mcscanx %d &> /dev/null"%(script_dir, cds, gff3, threads)
		time_print("\tRunning: %s"%cmd)
		os.system(cmd)
	else:
		time_print("\tMCScanX result found, skip")
	if not os.path.exists(dup_dir):
		cmd = "DupGen_finder-unique.pl -i %s -t xyz -c xyz -o %s &> /dev/null"%(parent_dir, dup_dir)
		time_print("\tRunning: %s"%cmd)
		os.system(cmd)
	else:
		time_print("\tDupGen_finder result found, skip")
	
	
	
	time_print("Step2: running gmap")
	gmap_res = "02.gmap/gmap.gff3"
	if not os.path.exists(gmap_res):
		cmd = "python %s/run_gmap.py %s %s %d 02.gmap %d &> /dev/null"%(script_dir, ref, cds, na, threads)
		time_print("\tRunning: %s"%cmd)
		os.system(cmd)
	else:
		time_print("\tGmap result found, skip")
	##############################################################
	
	
	
	time_print("Step3: Generating first allele table")
	if not os.path.exists("backbone.csv"):
		time_print("\tLoading MCScanX results")
		base_allele = []
		# laod synteny block by chromosome.
		# Load duplication infomation
		pDic, pLst, tDic, tLst = dp.merge_dup_class(dup_dir)
		#### EDIT HERE #### 
		
		
		for fn in os.listdir(mcs_dir):
			full_fn = os.path.join(mcs_dir, fn)
			tmp_allele = ab.get_allele_with_mcscanx(full_fn)
			base_allele.extend(tmp_allele)
		
		time_print("\tLoading GMAP result")
		# load gmap annotation results.
		gff3_db, gene_order = ag.read_gff3(gmap_res)
		gff3_allele = ag.allele_gmap(gff3_db, threads)
		base_allele.extend(gff3_allele)

		time_print("\tWriting allele list backbone")
		gff3_db, gene_order = ag.read_gff3(gff3)
		base_allele = ab.split_allele(base_allele, gene_order)
		base_allele = ab.merge_allele(base_allele)
		with open("backbone.csv", 'w') as fout:
			for allele in sorted(base_allele):
				fout.write("%s\n"%(",".join(sorted(allele))))
	else:
		time_print("\tallele list backbone found, loading")
		base_allele = []
		with open("backbone.csv", 'r') as fin:
			for line in fin:
				base_allele.append(line.strip().split(','))
	
	backbone = os.path.abspath("backbone.csv")
	final_allele = base_allele

	time_print("Step4: running blast")
	if not os.path.exists("03.blast"):
		os.mkdir("03.blast")
	time_print("\tEntering: blast")
	os.chdir("03.blast")

	for i in range(0, blast_count):
		time_print("\tStarting iteration %02d"%(i+1))
		outpre = "iter%02d"%(i+1)
		## single_fa are genes only with one allele.
		## multi_fa are genes with multi allleles.
		single_fa = outpre+"_single.fa"
		multi_fa = outpre+"_multi.fa"
		out_blast = outpre+".blast"
		if not(os.path.exists(single_fa) and os.path.exists(multi_fa)):
			cmd = "python %s/split_fasta_with_allele.py %s %s %s"%(script_dir, cds, backbone, outpre)
			time_print("\tRunning command: %s"%cmd)
			os.system(cmd)
		else:
			time_print("\tIter %02d, Fasta file found, skip"%(i+1))
		if not os.path.exists(out_blast):
			cmd1 = "makeblastdb -in %s -dbtype nucl -out blastdb%02d &> /dev/null"%(multi_fa, i+1)
			cmd2 = "blastn -query %s -db blastdb%02d -out %s -evalue 1e-3 -outfmt 6 -num_alignments 1 -num_threads %d &> /dev/null"%(single_fa, i+1, out_blast, threads)
			time_print("\tRunning command: %s"%cmd1)
			os.system(cmd1)
			time_print("\tRunning command: %s"%cmd2)
			os.system(cmd2)
		else:
			time_print("\tIter %02d, blast file found, skip"%(i+1))
		final_allele.extend(abl.allele_blast(out_blast, iden_thres))
		final_allele = ab.merge_allele(final_allele)
		backbone = outpre+".csv"
		if not os.path.exists(backbone):
			with open(backbone, 'w') as fout:
				for allele in sorted(final_allele):
					fout.write("%s\n"%(",".join(sorted(allele))))
	
	time_print("\tLeaving: 03.blast")
	os.chdir('..')

	time_print("Step5: Writing allele table")
	with open("allele.csv", 'w') as fout:
		for allele in sorted(final_allele):
			fout.write("%s\n"%(",".join(sorted(allele))))
	
	time_print("Step6: Adjusting with ref annotation")
	if not(os.path.exists("04.ref_adjust")):
		os.mkdir("04.ref_adjust")

	time_print("\tEntering: 04.ref_adjust")
	os.chdir("04.ref_adjust")

	ref_fn = ref_cds.split('/')[-1].split('.')[0]
	hap_fn = cds.split('/')[-1].split('.')[0]
	out_blast = hap_fn+'.vs.'+ref_fn+'.blast'
	if not os.path.exists(out_blast):
		cmd1 = "makeblastdb -in %s -dbtype nucl -out blastdb &> /dev/null"%(ref_cds)
		cmd2 = "blastn -query %s -db blastdb -out %s -evalue 1e-3 -outfmt 6 -num_alignments 1 -num_threads %d &> /dev/null"%(cds, out_blast, threads)
		time_print("\tRunning command: %s"%cmd1)
		os.system(cmd1)
		time_print("\tRunning command: %s"%cmd2)
		os.system(cmd2)
	else:
		time_print("\tBlast file found, skip")
	out_blast = os.path.abspath(out_blast)

	time_print("Leaving: 04.ref_adjust")
	os.chdir("..")
	
	allele_file = "allele.adjusted.txt"
	if not os.path.exists(allele_file):
		if is_mono:
			cmd = "python %s/adjust_allele_table_with_ref.py allele.csv %s %s %s %s %f %s %d allele.adjusted.txt T &> /dev/null"%(script_dir, ref_gff3, gff3, out_blast, hap_blast_file, iden_thres, tandem_file, na)
		else:
			cmd = "python %s/adjust_allele_table_with_ref.py allele.csv %s %s %s %s %f %s %d allele.adjusted.txt F &> /dev/null"%(script_dir, ref_gff3, gff3, out_blast, hap_blast_file, iden_thres, tandem_file, na)
		time_print("\tRunning command: %s"%cmd)
		os.system(cmd)
	else:
		time_print("\tallele.adjusted.txt found, skip")
	
	
	step_idx = 7
	if TE != "":
		time_print("Step7: Filtering with TEs")
		allele_file = "allele.adjusted.nonTEs.txt"
		if not os.path.exists(allele_file):
			cmd = "python %s/filter_with_TE.py allele.adjusted.txt %s %s %f allele.adjusted.nonTEs.txt &> /dev/null"%(script_dir, gff3, TE, TE_thres)
			time_print("\tRunning command: %s"%cmd)
			os.system(cmd)
			step_idx += 1
		else:
			time_print("\tallele.adjusted.nonTEs.txt found, skip")
	
	time_print("Step%d: Statistics"%step_idx)
	stat_pre = '.'.join(allele_file.split('.')[:-1])
	cmd = "python %s/stat_allele_info.py %s %s %s &> /dev/null"%(script_dir, allele_file, gff3, stat_pre)
	time_print("\tRunning command: %s"%cmd)
	os.system(cmd)

	time_print("Finished")


if __name__ == "__main__":
	opts = get_opts()
	ref = opts.ref
	ref_cds = opts.ref_cds
	ref_gff3 = opts.ref_gff3
	cds = opts.cds
	gff3 = opts.gff3
	if opts.is_mono:
		is_mono = True
	else:
		is_mono = False
	na = opts.num_allele
	blast_count = opts.blast_count
	iden_thres = opts.blast_identity
	TE = opts.TE
	TE_thres = opts.TE_overlap
	wrkdir = opts.workdir
	threads = opts.threads
	AlleleFinder(ref, ref_cds, ref_gff3, cds, gff3, na, is_mono, blast_count, iden_thres, TE, TE_thres, wrkdir, threads)
